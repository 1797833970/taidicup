{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd4f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027eb022",
   "metadata": {},
   "source": [
    "## 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca916422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据读取\n",
    "columns_to_int16 = ['日期', '时间', '生产线编号', '物料推送气缸状态', '物料推送数', '物料待抓取数', '放置容器数', '容器上传检测数',\n",
    "                    '填装检测数', '填装定位器状态', '物料抓取数', '填装旋转数', '填装下降数', '填装数', '加盖检测数', \n",
    "                    '加盖定位数', '推盖数', '加盖下降数', '加盖数', '拧盖检测数', '拧盖定位数', '拧盖下降数', '拧盖旋转数', \n",
    "                    '拧盖数', '合格数', '不合格数','机器状态']\n",
    "columns_to_int32 = ['0_Duration', '1_Duration', '2_Duration', '3_Duration', '4_Duration', '5_Duration', \n",
    "                    '6_Duration', '7_Duration', '8_Duration', '9_Duration', '10_Duration']\n",
    "\n",
    "def transfer_data_int(df):\n",
    "    df[columns_to_int16] = df[columns_to_int16].astype('Int16')\n",
    "    df[columns_to_int32] = df[columns_to_int32].astype('Int32')\n",
    "    return df\n",
    "\n",
    "def load_and_convert(file_paths):\n",
    "    \"\"\"批量读取 CSV 并转换类型，返回字典\"\"\"\n",
    "    return {fp.stem: transfer_data_int(pd.read_csv(fp)) for fp in file_paths}\n",
    "\n",
    "# 处理结果\n",
    "processed_files = list(Path('temp_data/train').glob('M*.csv'))\n",
    "train_data = load_and_convert(processed_files[:8])\n",
    "dev_data = load_and_convert(processed_files[8:])\n",
    "\n",
    "# 预测数据\n",
    "predicted_files = list(Path('temp_data/test').glob('M*.csv'))\n",
    "test_data = load_and_convert(predicted_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559e1f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征筛选\n",
    "feature_columns = ['物料推送气缸状态', '物料推送数', '物料待抓取数', '放置容器数', '容器上传检测数', '填装检测数',\n",
    "       '填装定位器状态', '物料抓取数', '填装旋转数', '填装下降数', '加盖检测数', '加盖定位数', '推盖数',\n",
    "       '加盖下降数', '拧盖检测数', '拧盖定位数', '拧盖下降数', '拧盖旋转数', '拧盖数', #'合格数','不合格数',\n",
    "       '0_Duration', '1_Duration', '2_Duration', '3_Duration',\n",
    "       '4_Duration', '5_Duration', '6_Duration', '7_Duration', '8_Duration',\n",
    "       '9_Duration', '10_Duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4168bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat(train_data.values(), ignore_index=True)\n",
    "dev_data = pd.concat(dev_data.values(), ignore_index=True)\n",
    "\n",
    "X_train, y_train = train_data[feature_columns], train_data['机器状态']\n",
    "X_dev, y_dev = dev_data[feature_columns], dev_data['机器状态']\n",
    "\n",
    "X_test_1, y_test_1 = test_data[\"M201\"][feature_columns],test_data[\"M201\"]['机器状态']\n",
    "X_test_2, y_test_2 = test_data[\"M202\"][feature_columns],test_data[\"M202\"]['机器状态']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88c25b9",
   "metadata": {},
   "source": [
    "## 模型评估指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247d73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "# 故障准确率\n",
    "def Fault_Accuracy(y_,y_pred_):\n",
    "    y_np = np.array(y_).astype(int)\n",
    "    y_pred_np = np.array(y_pred_).astype(int)\n",
    "    fault_index = np.where(y_np!= 0)[0]\n",
    "    \n",
    "    fault_accuracy = accuracy_score(y_np[fault_index],y_pred_np[fault_index])\n",
    "    return fault_accuracy\n",
    "\n",
    "# 报警准确率（不管报警内容是否正确）\n",
    "def Warning_Accuracy(y_,y_pred_):\n",
    "    y_np = np.array(y_).astype(int)\n",
    "    y_pred_np = np.array(y_pred_).astype(int)\n",
    "    \n",
    "    y_np[y_np != 0] = 1\n",
    "    y_pred_np[y_pred_np != 0] = 1\n",
    "\n",
    "    warning_accuracy = accuracy_score(y_np,y_pred_np)\n",
    "    return warning_accuracy\n",
    "\n",
    "def Recall(y_,y_pred_):\n",
    "    fault_labels = list(range(10))\n",
    "    y_np = np.array(y_).astype(int)\n",
    "    y_pred_np = np.array(y_pred_).astype(int)\n",
    "\n",
    "    recalls = recall_score(y_np, y_pred_np, average=None,labels=fault_labels)\n",
    "    print(\"单个类别的召回率:\")\n",
    "    labeled_recalls = {int(label): float(recall) for label, recall in zip(fault_labels, recalls)}\n",
    "    # 打印结果\n",
    "    for label, recall in labeled_recalls.items():\n",
    "        print('%d : %.4f '%(label,recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bdbcaa",
   "metadata": {},
   "source": [
    "## 采样策略 （SMOTE-Tomek 方法）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d57d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter  \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# smote重采样\n",
    "def smote_resample(X_train,y_train,sampling_strategy):\n",
    "\n",
    "    # 检查原始数据集的类别分布\n",
    "    original_counter = Counter(y_train)\n",
    "    print(\"Original dataset shape\", original_counter)\n",
    "\n",
    "    # 定义SMOTE对象，并应用上述采样策略\n",
    "    smote = SMOTE(random_state=42, k_neighbors=5, sampling_strategy=sampling_strategy)\n",
    "\n",
    "    # 对训练数据进行SMOTE过采样  \n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)  \n",
    "\n",
    "    # 检查SMOTE过采样后的类别分布  \n",
    "    resampled_counter = Counter(y_resampled)\n",
    "    print(\"SMOTE resampled dataset shape\", resampled_counter)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# 欠采样\n",
    "def undersample(X, y):\n",
    "    # 检查原始数据集的类别分布\n",
    "    original_counter = Counter(y)\n",
    "    print(\"Original dataset shape\", original_counter)\n",
    "\n",
    "    # 分离多数类和少数类\n",
    "    X_majority = X[y == 0]\n",
    "    y_majority = y[y == 0]\n",
    "    X_minority = X[y != 0]\n",
    "    y_minority = y[y != 0]\n",
    "\n",
    "    # 计算需要从多数类中删除的样本数量\n",
    "    num_to_remove = int(len(X_majority)/10)\n",
    "\n",
    "    # 随机选择要删除的样本\n",
    "    indices_to_remove = np.random.choice(len(X_majority), num_to_remove, replace=False)\n",
    "\n",
    "    # 选择样本\n",
    "    X_majority = X_majority.iloc[indices_to_remove]\n",
    "    y_majority = y_majority.iloc[indices_to_remove]\n",
    "\n",
    "    # 合并数据集\n",
    "    X_undersampled = pd.concat((X_majority, X_minority), ignore_index=True)\n",
    "    y_undersampled = pd.concat((y_majority, y_minority), ignore_index=True)\n",
    "\n",
    "    # 打乱数据集\n",
    "    X_undersampled, y_undersampled = shuffle(X_undersampled, y_undersampled, random_state=42)\n",
    "\n",
    "    # 检查SMOTE过采样后的类别分布  \n",
    "    undersampled_counter = Counter(y_undersampled)\n",
    "    print(\"undersample dataset shape\", undersampled_counter)\n",
    "\n",
    "    return X_undersampled, y_undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 故障可视化\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "values = X_train.value_counts()[1:]\n",
    "categories = X_train.value_counts()[1:].index\n",
    "\n",
    "# 将matplotlib的日志级别设置为'ERROR'，以屏蔽'WARNING'级别的信息\n",
    "logging.getLogger('matplotlib').setLevel(logging.ERROR)\n",
    "\n",
    "myfont = font_manager.FontProperties(fname='/home/aistudio/external-libraries/Fonts/SIMHEI.TTF')\n",
    "# 创建条形图\n",
    "bars = plt.bar(categories, values)\n",
    "\n",
    "# 自定义图表\n",
    "plt.title('故障统计',fontproperties=myfont)\n",
    "plt.xlabel('故障类别',fontproperties=myfont) \n",
    "plt.ylabel('Values')\n",
    "plt.xticks(categories)\n",
    "\n",
    "# 遍历每个条形，添加数量标签\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()  # 获取条形的高度（数量）\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.1, str(yval), \n",
    "             ha='center', va='bottom')  # 在条形上方添加文本\n",
    "\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a724bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_strategy = {\n",
    "    6: 50000, \n",
    "    8: 50000, \n",
    "    9: 50000, \n",
    "}\n",
    "X_train,y_train = train_data[feature_columns], train_data['机器状态']\n",
    "X_test_1, y_test_1 = test_data[\"M201\"][feature_columns],test_data[\"M201\"]['机器状态']\n",
    "X_test_2, y_test_2 = test_data[\"M202\"][feature_columns],test_data[\"M202\"]['机器状态']\n",
    "\n",
    "X_train, y_train = smote_resample(X_train, y_train, sampling_strategy)\n",
    "X_train, y_train = undersample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fcbfde",
   "metadata": {},
   "source": [
    "## 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import catboost as cat\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.svm as svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold,train_test_split,cross_val_score as CVS\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,confusion_matrix,mean_squared_error,recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db307a9",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建XGBoost分类器的基础设置  \n",
    "xgb_base = XGBClassifier(objective = 'multi:softmax',num_class = 10)  \n",
    "\n",
    "# 定义要搜索的超参数分布  \n",
    "param_distributions = {\n",
    "    'n_estimators': sp_randint(100,300),  \n",
    "    'learning_rate': [0.05, 0.08, 0.1], \n",
    "    'max_depth': range(3,10,2),\n",
    "    'subsample': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# 使用 make_scorer 包装自定义评分函数\n",
    "scorer = make_scorer(Fault_Accuracy)\n",
    "\n",
    "# 创建随机搜索对象  \n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_base,  \n",
    "    param_distributions = param_distributions,  \n",
    "    n_iter=10,  # 尝试的参数组合数量  \n",
    "    scoring = scorer,  \n",
    "    cv=5,  # 交叉验证的折数  \n",
    "    n_jobs=-1,  # 使用所有可用的CPU核心\n",
    "    verbose=10,  # 输出进度信息\n",
    "    random_state=1024,\n",
    ")  \n",
    "\n",
    "# 使用编码后的标签和特征数据训练模型，并进行超参数搜索\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29118e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取最佳参数\n",
    "xbg_best_params = random_search.best_params_  \n",
    "print(\"Best Parameters: \", xbg_best_params)\n",
    "\n",
    "# 获取最佳模型  \n",
    "best_xgb = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850492b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "              objective = 'multi:softmax',\n",
    "              max_depth = 9,\n",
    "              n_estimators = 170, \n",
    "              num_class = 10,\n",
    "              learning_rate=0.08,\n",
    "              subsample = 0.6,\n",
    "              verbose=-1,)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_dev)\n",
    "\n",
    "print('Accuracy : %.6f' % (accuracy_score(y_dev, y_pred)))\n",
    "print('Fault_Accuracy : %.6f' % (Fault_Accuracy(y_dev, y_pred)))\n",
    "print('Warning_Accuracy : %.6f' % (Warning_Accuracy(y_dev, y_pred)))\n",
    "Recall(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混淆矩阵\n",
    "cm = confusion_matrix(y_dev, y_pred)\n",
    "\n",
    "# 使用 Seaborn 绘制混淆矩阵的热图\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Serif']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "# 设置图表标题和坐标轴标签\n",
    "plt.title('confusion_matrix')\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel('y_dev')\n",
    "\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e5c650",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44059883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建随机森林分类器  \n",
    "rf_base = RandomForestClassifier(random_state=1024) \n",
    "\n",
    "param_dist = {  \n",
    "    \"n_estimators\": sp_randint(100, 300),  \n",
    "    \"max_depth\": sp_randint(3, 10),  \n",
    "    \"max_features\": sp_randint(1, 11),  \n",
    "    \"min_samples_split\": sp_randint(2, 11),  \n",
    "}\n",
    "\n",
    "# 使用 make_scorer 包装自定义评分函数\n",
    "scorer = make_scorer(Fault_Accuracy)\n",
    "\n",
    "# 创建随机搜索对象  \n",
    "random_search = RandomizedSearchCV(  \n",
    "    estimator=rf_base,  \n",
    "    param_distributions=param_dist,  \n",
    "    n_iter=20,  # 尝试10组不同的参数\n",
    "    scoring = scorer,  \n",
    "    cv=5,  # 使用5折交叉验证  \n",
    "    n_jobs=-1,  # 使用所有可用的处理器  \n",
    "    random_state=1024,\n",
    "    verbose = 10\n",
    ")\n",
    "\n",
    "# 使用编码后的标签和特征数据训练模型，并进行超参数搜索\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取最佳参数\n",
    "rf_best_params = random_search.best_params_  \n",
    "print(\"Best Parameters: \", rf_best_params)\n",
    "\n",
    "# 获取最佳模型  \n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_dev)\n",
    "\n",
    "print('Accuracy : %.6f' % (accuracy_score(y_dev, y_pred)))\n",
    "print('Fault_Accuracy : %.6f' % (Fault_Accuracy(y_dev, y_pred)))\n",
    "print('Warning_Accuracy : %.6f' % (Warning_Accuracy(y_dev, y_pred)))\n",
    "Recall(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b28b12",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b9182",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 初始化CatBoost分类器  \n",
    "cat_base = CatBoostClassifier(loss_function='MultiClass', early_stopping_rounds=50,random_state=1024,verbose = 300)  \n",
    "\n",
    "# 定义超参数搜索空间  \n",
    "param_grid = {  \n",
    "    'iterations': [500, 800, 1000],  \n",
    "    'learning_rate': [0.03, 0.05, 0.08],  \n",
    "    'depth': [5, 6, 8],  \n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# 使用 make_scorer 包装自定义评分函数\n",
    "scorer = make_scorer(Fault_Accuracy)\n",
    "\n",
    "# 使用RandomizedSearchCV进行超参数调优  \n",
    "random_search = RandomizedSearchCV(  \n",
    "    estimator=cat_base,  \n",
    "    param_distributions=param_grid,  \n",
    "    n_iter=10,  # 尝试10组不同的超参数组合\n",
    "    cv=5,  # 使用5折交叉验证\n",
    "    scoring = scorer,  # 根据自定义评分函数来评价模型性能  \n",
    "    n_jobs=-1,  # 使用所有可用的CPU核心\n",
    "    random_state=1024,\n",
    "    verbose = 10\n",
    ")\n",
    "\n",
    "# 使用编码后的标签和特征数据训练模型，并进行超参数搜索\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46581b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取最佳参数\n",
    "cat_best_params = random_search.best_params_  \n",
    "print(\"Best Parameters: \", cat_best_params) \n",
    "\n",
    "# 获取最佳模型\n",
    "best_cat = random_search.best_estimator_  \n",
    "y_pred_cat = best_cat.predict(X_dev)  \n",
    "  \n",
    "# 输出分类报告  \n",
    "print('Accuracy : %.6f' % (accuracy_score(y_dev, y_pred_cat)))\n",
    "print('Fault_Accuracy : %.6f' % (Fault_Accuracy(y_dev, y_pred_cat)))\n",
    "print('Warning_Accuracy : %.6f' % (Warning_Accuracy(y_dev, y_pred_cat)))\n",
    "Recall(y_dev, y_pred_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4aaf83",
   "metadata": {},
   "source": [
    "## Soft Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b20c5",
   "metadata": {},
   "source": [
    "### 交叉验证+Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a408621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gc\n",
    "\n",
    "def build_model(model_type):\n",
    "    if model_type == \"lgb\":\n",
    "        return LGBMClassifier(\n",
    "            objective=\"multiclass\",\n",
    "            num_class=10,\n",
    "            n_estimators=300\n",
    "        )\n",
    "\n",
    "    elif model_type == \"xgb\":\n",
    "        return XGBClassifier(\n",
    "            objective=\"multi:softprob\",\n",
    "            num_class=10,\n",
    "            learning_rate=0.08,\n",
    "            eval_metric=\"mlogloss\"\n",
    "        )\n",
    "\n",
    "    elif model_type == \"cat\":\n",
    "        return CatBoostClassifier(\n",
    "            iterations=500,\n",
    "            verbose=0,\n",
    "            loss_function=\"MultiClass\"\n",
    "        )\n",
    "\n",
    "    elif model_type == \"rf\":\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=300,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "    elif model_type == \"lr\":\n",
    "        return LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            multi_class=\"multinomial\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type\")\n",
    "    \n",
    "def cv_model(data_, test_, y_, model_type, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    n_classes = len(np.unique(y_))\n",
    "    oof_preds = np.zeros((len(data_), n_classes))\n",
    "    test_preds = np.zeros((len(test_), n_classes))\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(data_, y_)):\n",
    "        print(f\"\\n===== Fold {fold+1} =====\")\n",
    "\n",
    "        X_tr, y_tr = data_.iloc[tr_idx], y_.iloc[tr_idx]\n",
    "        X_val, y_val = data_.iloc[val_idx], y_.iloc[val_idx]\n",
    "\n",
    "        model = build_model(model_type)\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        oof_preds[val_idx] = model.predict_proba(X_val)\n",
    "        test_preds += model.predict_proba(test_) / n_splits\n",
    "\n",
    "        val_pred = np.argmax(oof_preds[val_idx], axis=1)\n",
    "\n",
    "        print(\"Acc:\", accuracy_score(y_val, val_pred))\n",
    "        print(\"Fault Acc:\", Fault_Accuracy(y_val, val_pred))\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "    print(\"\\n===== Overall =====\")\n",
    "    final_pred = np.argmax(oof_preds, axis=1)\n",
    "    print(\"Acc:\", accuracy_score(y_, final_pred))\n",
    "    print(\"Fault Acc:\", Fault_Accuracy(y_, final_pred))\n",
    "    print(\"Warning Acc:\", Warning_Accuracy(y_, final_pred))\n",
    "    Recall(y_, final_pred)\n",
    "\n",
    "    return test_preds\n",
    "\n",
    "def cv_soft_voting(data_, test_, y_):\n",
    "    models = ['xgb', 'rf', 'cat']\n",
    "    voting_result = np.zeros((test_.shape[0], 10))\n",
    "    \n",
    "    for m in models:\n",
    "        print('=======================')\n",
    "        print(f\"Training {m} ...\")\n",
    "        sub_pred = cv_model(data_, test_, y_, model_type=m)\n",
    "        voting_result += sub_pred / len(models)\n",
    "        print(f\"{m} done.\")\n",
    "        print('=======================')\n",
    "    \n",
    "    pred = np.argmax(voting_result, axis=1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cv_voting = cv_soft_voting(X_train, X_dev, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b612ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy : %.6f' % (accuracy_score(y_dev, y_pred_cv_voting)))\n",
    "print('Fault_Accuracy : %.6f' % (Fault_Accuracy(y_dev, y_pred_cv_voting)))\n",
    "print('Warning_Accuracy : %.6f' % (Warning_Accuracy(y_dev, y_pred_cv_voting)))\n",
    "Recall(y_dev, y_pred_cv_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终预测，此处X_train仅是80%，实际预测时需使用所有数据\n",
    "y_preds_1, final_pred_1 = cv_soft_voting(X_train, X_test_1, y_train)\n",
    "y_preds_2, final_pred_2 = cv_soft_voting(X_train, X_test_2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff66964",
   "metadata": {},
   "source": [
    "### Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2785d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_model(data_, test_, y_, model_type):\n",
    "    n_classes = len(np.unique(y_))\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        model = LGBMClassifier(objective='multiclass', num_class=n_classes, verbose=-1)\n",
    "    elif model_type == 'xgb':\n",
    "        model = XGBClassifier(objective='multi:softprob', num_class=n_classes,\n",
    "                              learning_rate=0.08, max_depth=9, n_estimators=170,\n",
    "                              subsample=0.6, verbosity=0)\n",
    "    elif model_type == 'cat':\n",
    "        model = CatBoostClassifier(iterations=1000, learning_rate=0.03, depth=6,\n",
    "                                   l2_leaf_reg=3, verbose=500, random_state=42,\n",
    "                                   loss_function='MultiClass')\n",
    "    elif model_type == 'rf':\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type\")\n",
    "\n",
    "    model.fit(data_, y_)\n",
    "    y_pred_ = model.predict(test_)\n",
    "    sub_pred_ = model.predict_proba(test_)\n",
    "\n",
    "    return y_pred_, sub_pred_\n",
    "\n",
    "def soft_voting(data_, test_, y_):\n",
    "    models = ['xgb', 'rf', 'cat']\n",
    "    n_classes = len(np.unique(y_))\n",
    "    voting_result = np.zeros((test_.shape[0], n_classes))\n",
    "    y_preds = []\n",
    "\n",
    "    for m in models:\n",
    "        print(f\"Training {m} ...\")\n",
    "        y_pred, sub_pred = voting_model(data_, test_, y_, model_type=m)\n",
    "        y_preds.append(y_pred)\n",
    "        voting_result += sub_pred / len(models)\n",
    "\n",
    "    final_pred = np.argmax(voting_result, axis=1)\n",
    "    return y_preds, final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceeb2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds, y_pred_voting = soft_voting(X_train, X_dev, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f7c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy : %.6f' % (accuracy_score(y_dev, y_pred_voting)))\n",
    "print('Fault_Accuracy : %.6f' % (Fault_Accuracy(y_dev, y_pred_voting)))\n",
    "print('Warning_Accuracy : %.6f' % (Warning_Accuracy(y_dev, y_pred_voting)))\n",
    "Recall(y_dev, y_pred_voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2fb58f",
   "metadata": {},
   "source": [
    "## stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基分类器\n",
    "lgb_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 10,\n",
    "    'verbose':-1,\n",
    "    'n_estimators':100}\n",
    "\n",
    "models = [\n",
    "        XGBClassifier(\n",
    "            objective = 'multi:softmax',\n",
    "            num_class = 10,\n",
    "            earning_rate=0.08,\n",
    "            verbose=-1,\n",
    "            ),\n",
    "\n",
    "        CatBoostClassifier(\n",
    "            iterations=1000,  # 最大迭代次数\n",
    "            learning_rate=0.03,  # 学习率\n",
    "            depth=6,  # 树的最大深度\n",
    "            l2_leaf_reg=3,  # L2 正则化参数\n",
    "            loss_function='MultiClass',  # 损失函数\n",
    "            thread_count=4,  # 线程数\n",
    "            random_state=42,  # 随机种子\n",
    "            early_stopping_rounds=50,  # 早停的迭代次数\n",
    "            verbose = 300,\n",
    "            ),\n",
    "\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5d479",
   "metadata": {},
   "source": [
    "### 交叉验证+stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b63dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cv_stacking_model(data_, test_, y_, models):\n",
    "    n_classes = len(np.unique(y_))\n",
    "    X_train_stack = np.zeros((data_.shape[0], len(models) * n_classes))\n",
    "    X_test_stack = np.zeros((test_.shape[0], len(models) * n_classes))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for i, base_model in enumerate(models):\n",
    "        print(f\"Training base model {i+1}/{len(models)} ...\")\n",
    "        X_test_stack_fold = np.zeros((test_.shape[0], n_classes))\n",
    "\n",
    "        for fold, (tr_idx, val_idx) in enumerate(skf.split(data_, y_)):\n",
    "            print(f\"Fold {fold+1}\")\n",
    "            tr_x, tr_y = data_.iloc[tr_idx], y_.iloc[tr_idx]\n",
    "            val_x, val_y = data_.iloc[val_idx], y_.iloc[val_idx]\n",
    "\n",
    "            # 每折重新复制模型\n",
    "            model = deepcopy(base_model)\n",
    "            \n",
    "            # CatBoost 早停需要传 eval_set\n",
    "            if isinstance(model, CatBoostClassifier):\n",
    "                model.fit(tr_x, tr_y, eval_set=(val_x, val_y))\n",
    "            else:\n",
    "                model.fit(tr_x, tr_y)\n",
    "\n",
    "            proba_val = model.predict_proba(val_x)\n",
    "            proba_test = model.predict_proba(test_)\n",
    "\n",
    "            X_train_stack[val_idx, i*n_classes:(i+1)*n_classes] = proba_val\n",
    "            X_test_stack_fold += proba_test / skf.n_splits\n",
    "\n",
    "            print('accuracy : %.6f    Fault_Accuracy : %.6f' % \n",
    "                  (accuracy_score(val_y, np.argmax(proba_val, axis=1)), \n",
    "                   Fault_Accuracy(val_y, np.argmax(proba_val, axis=1))))\n",
    "\n",
    "        # 填充每个模型 stacking 测试集\n",
    "        X_test_stack[:, i*n_classes:(i+1)*n_classes] = X_test_stack_fold\n",
    "\n",
    "    # 第二层\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr.fit(X_train_stack, y_)\n",
    "    final_pred = lr.predict(X_test_stack)\n",
    "\n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cv_stacking = cv_stacking_model(X_train, X_dev, y_train, models)\n",
    "print('Accuracy : %.6f' % (accuracy_score(y_dev, y_pred_cv_stacking)))\n",
    "print('Fault_Accuracy : %.6f' % (Fault_Accuracy(y_dev, y_pred_cv_stacking)))\n",
    "print('Warning_Accuracy : %.6f' % (Warning_Accuracy(y_dev, y_pred_cv_stacking)))\n",
    "Recall(y_dev, y_pred_cv_stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b0754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终预测，此处X_train仅是80%，实际预测时需使用所有数据\n",
    "y_preds_1, final_pred_1 = cv_stacking_model(X_train, X_test_1, y_train, models)\n",
    "y_preds_2, final_pred_2 = cv_stacking_model(X_train, X_test_2, y_train, models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a491adba",
   "metadata": {},
   "source": [
    "### stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f08649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking_model(data_, test_, y_, models):\n",
    "    n_classes = len(np.unique(y_))\n",
    "    X_train_stack = np.zeros((data_.shape[0], len(models)*n_classes))\n",
    "    X_test_stack = np.zeros((test_.shape[0], len(models)*n_classes))\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Training model {i+1}/{len(models)}\")\n",
    "        model.fit(data_, y_)\n",
    "        \n",
    "        # 训练集和测试集 stacking 特征\n",
    "        X_train_stack[:, i*n_classes:(i+1)*n_classes] = model.predict_proba(data_)\n",
    "        X_test_stack[:, i*n_classes:(i+1)*n_classes] = model.predict_proba(test_)\n",
    "\n",
    "        # 训练集准确率（调试用）\n",
    "        y_data = np.argmax(X_train_stack[:, i*n_classes:(i+1)*n_classes], axis=1)\n",
    "        print(f\"Training accuracy: {accuracy_score(y_, y_data):.6f}, Fault_Accuracy: {Fault_Accuracy(y_, y_data):.6f}\")\n",
    "\n",
    "    # 第二层\n",
    "        lr = LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        solver='lbfgs',\n",
    "        penalty='l2', \n",
    "        C=1.0,\n",
    "        )\n",
    "    lr.fit(X_train_stack, y_)\n",
    "    pred = lr.predict(X_test_stack)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa854a55",
   "metadata": {},
   "source": [
    "## 预测结果保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaedce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"M201\"]['机器状态'] = final_pred_1\n",
    "test_data[\"M202\"]['机器状态'] = final_pred_2\n",
    "\n",
    "test_data[\"M201\"].to_csv('result/M201.csv', index=False)\n",
    "test_data[\"M202\"].to_csv('result/M202.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
